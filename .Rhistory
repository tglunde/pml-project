max(abs(e - (y - coef(fit){1} - coef(fit){2} * x)))
max(abs(e - (y - coef(fit)1 - coef(fit)2 * x)))
max(abs(e - (y - coef(fit)1 - coef(fit)2 * x)))
plot(x,y) ; abline(lm(y-x))
plot(x,y) ; abline(lm(y~x))
plot(x,resid(fit))
plot(x,resid(fit)); abline(h=0)
x <- runif(100,0,6); y <- x + rnorm(100,mean=0,sd=.001*x);
plot(x,y); abline(lm(y - x))
plot(x,y); abline(lm(y ~ x))
plot(x,resid(lm(y~x)))
y <- diamond$price ; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
summary(fit)$sigma
sqrt(sum(resid(fit)^2)/(n-2))
data(anscombe)
example(anscombe)
cor(y,x)
cor(c,y)
cor(x,y)
y <- diamond$price ; x <- diamond$carat; n <- length(y)
beta1 <- cor(y,x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - beta0 - beta1*x
sigma <- sqrt(sum(e^2) / (n-2))
ssx <- sum(x-mean(x)^1)
setBeta0 <- (1/n + mean(x)^2 / ssx) ^.5 * sigma
seBeta0 <- (1/n + mean(x)^2 / ssx) ^.5 * sigma
seBeta1 y<- sigma / sqrt(ssx)
seBeta1 <- sigma / sqrt(ssx)
tBeta0 <- beta0 / seBeta0; tBeat1 <- beta1/seBeta1
pBeta0 <- pt(abs(tBeta0), df=n-2,lower.tail=FALSE)
pBeta1 <- pt(abs(tBeta1), df=n-2,lower.tail=FALSE)
tBeta0 <- beta0 / seBeta0; tBeta1 <- beta1/seBeta1
pBeta1 <- pt(abs(tBeta1), df=n-2,lower.tail=FALSE)
coefTable <- rbind(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, pBeta1))
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, pBeta1))
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std.Error","t value","P(>t)")
rownames(coefTable) <- c("Intercept", "x")
coefTable
fit <- lm(y ~ c)
fit <- lm(y ~ x)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
fit$df
n
galton
install.packags("caret")
install.packages("caret")
library(caret); library(kernlab);data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
trainign <- spam[inTrain,]
View(trainign)
View(trainign)
View(trainign)
View(trainign)
testing <- spam[~inTrain,]
testing <- spam[-inTrain,]
dim(training)
dim(trainign)
set.seed(32343)
modelFit <- train(type ~., data=trainign, method='glm')
install.packages('e1071')
modelFit <- train(type ~., data=trainign, method='glm')
warnings()
modelFit
?train
modelFit$finalModel
predictions <- predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions, testing$type)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam{-inTrain,}
testing <- spam[-inTrain,]
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)
sapply(fold,length)
sapply(folds,length)
folds[[1]][1:10]
folds[[2]][1:10]
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=FALSE)
sapply(folds,length)
folds <- createResample(y=spam$type, times=10, list=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds <- createTimeSlices(y=1:1000,initialWindow=20,horizon=10)
names(flds)
names(folds)
folds$train[[1]]
modelFit <- train(type ~., data=training, method='glm')
args(trainControl)
args(train)
args(train.default)
args(defaultSummary)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot="pairs")
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
test <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
mean(training$capitalAve)
sd(training$capitalAve)
?preProcess
str(wage)
str(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=.7,list=FALSE)
training <- Wage[inTrain,];testing<-Wage[-inTrain,]
table(training$jobclass)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bBasis
bsBasis
plot(training$wage,training$age,pch=19,ex=.5)
plot(training$age,training$wage,pch=19,ex=.5)
points(training$age,predict(lm(wage~bsBasis,data=training),newdata=training),col="red",pch=19,cex=.5)
?gam
??gam
?caret::gam
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
?diag
which(M > 0.8, arr.ind=T)
names(spam)[C(34,32)]
names(spam)[c(34,32)]
plot(spam[,34],spam[,c(32)])
plot(spam[,40],spam[,c(32)])
X <- .71*training$num415 + .71*num857
X <- .71*training$num415 + .71*training$num857
Y <- .71*training$num415 - .71*training$num857
plot(X,Y)
small <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
prComp <- prcomp(small)
str(prComp)
strComp
prComp
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2], col=typeColor, xlab="PC1", xlab="PC2")
plot(prComp$x[,1],prComp$x[,2], col=typeColor)
pre <- preProcess(log10(spam[,-58]+1), mehod="pca", pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
spamPC <- predict(pre,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2])
plot(spamPC[,1],spamPC[,2],col=typeColor)
pre <- preProcess(log10(spam[,-58]+1), mehod="pca", pcaComp=2)
library(caret);data(faithful);set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,p=.5,list=FALSE)
train <- faithful(inTraing,)
train <- faithful[inTraing,]
train <- faithful[inTrain,]
plot(train$waiting,train$eruptions)
lm1 <- lm(eruptions~waiting,data=train)
summary(lm)
summary(lm1)
lines(train$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
newdata
test <- faithful[-inTrain,]
sqrt(sum(lm1$fitted-train$eruptions)^2)
sqrt(sum((lm1$fitted-train$eruptions)^2))
sqrt(sum((lm1$fitted-train$eruptions)^2))
sqrt(sum((predict(lm1,newdata=test)-test$eruptions)^2))
data(Wages)
library(ISLR)
data(Wages)
data(Wage)
library(ggplot2);library(caret)
data(Wage)
Wage <- subset(Wage,select=c(logwage))
summary(Wage)
summary(Wage)
data(Wage)
Wage <- subset(Wage,select=c(-logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list=FALSE)
training <- Wage[inTrain,]
test <- Wage[-inTrain,]
dim(training),dim(test)
dim(training);dim(test)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,color=jobclass,data=training)
qplot(age,wage,color=jobclass,data=training,pch=5)
qplot(age,wage,color=jobclass,data=training,cex=.8)
qplot(age,wage,color=education,data=training,cex=.8)
qplot(age,wage,color=education,data=training,cex=1.5)
qplot(age,wage,color=education,data=training)
modFit <- train(wage ~ age + jobclass + eduction, method="lm", data=training)
modFit <- train(wage ~ age + jobclass + education, method="lm", data=training)
print(modFit)
plot(finMod,1,pch=19,cex=.5,col='#00000010')
plot(modFit$finalModel,1,pch=19,cex=.5,col='#00000010')
qplot(modFit$finalModel$fitted)
qplot(modFit$finalModel$fitted,modFit$finalModel$residuals, colour=race,data=training)
plot(modFit$finalModel$residuals,pch=19)
pred <- predict(modFit,testing)
pred <- predict(modFit,test)
qplot(wage,pred,colour=year,data=testing)
qplot(wage,pred,colour=year,data=test)
library(AppliedPredictiveModeling);library(caret);data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling);library(caret);data(AlzheimerDisease)
adData <- data.frame(diagnosis,predictors)
summary(adData)
str(adData)
library(AppliedPredictiveModeling);library(caret);data(AlzheimerDisease)
str(diagnosis)
summary(diagnosis)
plot(diagnosis)
adData <- data.frame(diagnosis,predictors)
trainIndex <- createDataPartition(diagnosis,p=.5,list=FALSE)
train <- adData[trainIndex,]
test <- adData[-trainIndex,]
data(concrete)
set.seed(975)
inTrain<-createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]]
train <- mixtures[inTrain,]
test <- mixtures[-inTrain,]
plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength,age)
plot(mixtures$CompressiveStrength,mixtures$age)
plot(mixtures$CompressiveStrength,mixtures$age)
plot(mixtures$CompressiveStrength,mixtures$FlyAsh)
plot(mixtures$FlyAsh,mixtures$CompressiveStrength)
featurePlot(train$CompressiveStrength,train[,c("FlyAsh")])
featurePlot(train$CompressiveStrength,train)
plot(mixtures,mixtures$CompressiveStrength)
featurePlot(train)
featurePlot(train$CompressiveStrength,train)
str(train)
train[,-9]
featurePlot(x=train[,-9],y=train$CompressiveStrength)
featurePlot(x=train[,-9],y=train$CompressiveStrength,plot="pairs")
str(training)
str(train)
plot(train[,-9])
plot(train[,9])
points(train[,1],col="red")
points(train[,2],col="red")
points(train[,2],col="blue")
points(train[,3],col="green")
points(train[,4],col="brown")
points(train[,5],col="yellow")
points(train[,6],col="yellow")
points(train[,7],col="yellow")
points(train[,8],col="yellow")
data(concrete)
library(caret)
set.seed(975)
inTrain <- createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]]
inTrain
training <- mixtures[inTrain]
inTrain <- createDataPartition(mixtures$CompressiveStrength,p=3/4)[[1]]
training <- mixtures[inTrain,]
test <- mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
summary(training$Superplasticizer)
hist(log10(training$Superplasticizer+1))
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer)+10)
set.seed(3433)
data(AlzheimerDisease)
adData <- data.frame(diagnosis,predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain,]
testing <- adData[-inTrain,]
training[,cgrep("IL")]
training[,grepl("IL%")]
training[,grepl("IL%",colnames(training))]
training[,grepl("IL*",colnames(training))]
training[,grepl("^IL*",colnames(training))]
grepl("^IL",colnames(training))
str(training[,grepl("^IL",colnames(training))])
?preprocess
?preProcess
prep <- preProcess(training[,grepl("^IL",colnames(training))], method=c("center","scale"))
prep
str(prep)
prep <- preProcess(training[,grepl("^IL",colnames(training))], method="pca",pcaComp=2)
trainPC <- predict(prep,training)
trainPC <- predict(prep,training[, grepl("^IL", colnames(training))])
modelFit <- train(trainig$type ~ . , method="glm", data = trainPC)
modelFit <- train(training$type ~ . , method="glm", data = trainPC)
modelFit <- train(training$diagnosis ~ . , method="glm", data = trainPC)
confusionMatrix(training$diagnosis,predict(modelFit,trainPC))
modelFit <- train(training$diagnosis ~ . , method="glm", data = trainPC)
confusionMatrix(training$diagnosis,predict(modelFit,trainPC))
trainIL <- training[, grepl("^IL", colnames(training))]
str(trainIL)
str(training)
set.seed(3433)
data(AlzheimerDisease)
trainmod <- rbind(training$diagnosis,trainIL)
str(rainmod)
str(trainmod)
trainmod <- cbind(training$diagnosis,trainIL)
str(trainmod)
training <- adData[inTrain,]
trainIL <- training[, grepl("^IL", colnames(training))]
trainmod <- cbind(training$diagnosis,trainIL)
str(trainmod)
nonPCA <- train(trainmod$training$diagnosis ~ ., method="glm", data=trainmod)
colnames[1]<-'diagnosis'
nonPCA <- train(trainmod[,1] ~ ., method="glm", data=trainmod)
PCA <- train(trainmod[,1] ~ ., method="glm", preProcess="pca", data=trainmod)
confusionMatrix(testing$diagnosis, predict(nonPCA,testing))
confusionMatrix(testing[,1], predict(nonPCA,testing))
trainmod$diagnosis <- trainmod[,1]
nonPCA <- train(trainmod[,1] ~ ., method="glm", data=trainmod)
PCA <- train(trainmod[,1] ~ ., method="glm", preProcess="pca", data=trainmod)
confusionMatrix(testing$diagnosis, predict(nonPCA,testing))
trainmod <- cbind(training[,1],trainIL)
str(trainmod)
colnames(trainmod)[1]<-"diagnosis"
nonPCA <- train(trainmod$diagnosis ~ ., method="glm", data=trainmod)
PCA <- train(trainmod$diagnosis ~ ., method="glm", preProcess="pca", data=trainmod)
confusionMatrix(testing$diagnosis, predict(nonPCA,testing))
confusionMatrix(testing$diagnosis, predict(PCA,testing))
args(preProcess.default)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainmod <- cbind(training[,1],training[,grepl("^IL", colnames(training))])
str(trainmod)
colnames(trainmod)[1]
colnames(trainmod)[1] <- "diagonsis"
str(trainmod)
PCA <- train(trainmod$diagnosis ~ ., method="glm", preProcess="pca", data=trainmod)
str(trainmod)
PCA <- train(trainmod$diagnosis ~ ., method="glm", preProcess="pca", data=trainmod)
PCA <- train(trainmod$diagonsis ~ ., method="glm", preProcess="pca", data=trainmod)
args(preProcess.default)
PCA <- train(trainmod$diagonsis ~ ., method="glm", preProcess="pca", data=trainmod, thresh=.9)
prep <- preProcess(trainmod[,-1], method = "pca", thresh = .9)
prep
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
plot(training$CompressiveStrength, training$Superplasticizer)
hist(training$Superplasticizer)
plot(training$Superplasticizer, training$CompressiveStrength)
summary(training$Superplasticizer)
install.packages("Hmisc")
library(Hmisc)
cutSuper <- cut2(training$Superplasticizer, g=4)
table(cutSuper)
cutSuperLog <- cut2(log10(training$Superplasticizer), g=4)
table(cutSuperLog)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainmod <- cbind(training[,1],training[,grepl("^IL", colnames(training))])
colnames(trainmod)[1] <- "diagonsis"
str(trainmod)
pre <- preProcess(trainmod$diagonsis ~ ., method="pca", thresh = .8, data=trainmod)
pre <- preProcess(trainmod$diagonsis ~ ., method="pca", thresh = .8)
pre <- preProcess(trainmod$diagonsis ~ ., method="pca", thresh = .8)
pre <- preProcess(trainmod[,-1], method="pca", thresh = .8)
pre
pre <- preProcess(trainmod[,-1], method="pca", thresh = .8, outcome = trainmod$diagonsis)
pre
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", method = "curl", destfile="training.csv")
getwd()
setwd("/Users/tg/GitHub/pml-project/")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", method = "curl", destfile="training.csv")
training <- read.csv("training.csv")
summary(training)
hist(training$classe)
table(training$classe)
hist(table(training$classe))
table(training$classe)[2,]
dim(table(training$classe))
dim(table(training$classe))[1,]
dim(table(training$classe))[2]
dim(table(training$classe))[3]
dim(table(training$classe))[[1]]
dim(table(training$classe))[[2]]
dim(table(training$classe))[[1]]
str(table(training$classe))
prep <- preProcess(training[,-160], method="pca", thresh=.9)
prep <- preProcess(training[,-160 & isNumeric()], method="pca", thresh=.9)
prep <- preProcess(training[,-160 & is.numeric()], method="pca", thresh=.9)
prep <- preProcess(training[,-160 & is.numeric(.)], method="pca", thresh=.9)
prep <- preProcess(training[,is.numeric()], method="pca", thresh=.9)
prep <- preProcess(training[is.numeric(),], method="pca", thresh=.9)
prep <- preProcess(training[sapply(x,function(x) is.numeric(x)),], method="pca", thresh=.9)
prep <- preProcess(training[sapply(training,function(x) is.numeric(x)),], method="pca", thresh=.9)
prep <- preProcess(training[, sapply(training, class) %in% c('numeric')], method="pca", thresh=.9)
prep
str(prep)
prep <- preProcess(training[, sapply(training, class) %in% c('numeric')], method="pca", thresh=.95)
prep
dim(prep)
prep$dim
prep$cols
prep$cols[1]
prep
str(prep)
prep[7]
str(prep[7])
prep[7]$names
colnames(prep[7])
prep[7]$std
prep[7]$std$names
?preProcess
prep <- preProcess(training[, sapply(training, class) %in% c('numeric')], method="pca", thresh=.95, outcome = training[,160])
training[,160]
prep <- preProcess(training[, sapply(training, class) %in% c('numeric')], method="pca", thresh=.95, outcome = training[,160])
trainNumeric <- training[, sapply(training, class) %in% c('numeric')]
colnames(trainNumeric)
trainNumeric <- training[, sapply(training, class) %in% c('numeric') & 160]
colnames(trainNumeric)
trainNumeric <- training[, sapply(training, class) %in% c('numeric') && 160]
colnames(trainNumeric)
trainNumeric <- cbind(training[,160],training[, sapply(training, class) %in% c('numeric') ]
colnames(trainNumeric)
trainNumeric <- cbind(training[,160],training[, sapply(training, class) %in% c('numeric') ])
colnames(trainNumeric)
colnames(trainNumeric)[1]<-"classe"
colnames(trainNumeric)
str(classe)
str(trainNumeric)
summary(trainNu)
summary(trainNumeric)
prep <- preProcess(trainNumeric[,-1], method="pca", thresh=.95, outcome = trainNumeric$classe)
prep
predict(prep, trainNumeric)
prep <- preProcess(trainNumeric[,-1], method="pca", thresh=.95, outcome = trainNumeric$classe)
prep
trainpc <- predict(prep, trainNumeric[,-1])
confusionMatrix(trainNumeric$classe, trainingpc)
confusionMatrix(trainNumeric$classe, trainpc)
modelFit <- train(trainNumeric$classe ~ ., method="glm", data=trainpc)
modelFit <- train(trainNumeric$classe ~ ., method="glm", preProcess="pca", na.action="na.omit")
modelFit <- train(trainNumeric$classe ~ ., method="glm", preProcess="pca")
modelFit <- train(trainNumeric$classe ~ . , method="glm", preProcess="pca")
modelFit <- train(trainNumeric$classe ~ . , method="glm", preProcess="pca", data=training)
modelFit <- train(trainNumeric$classe ~ . , method="glm", preProcess="pca", data=trainNumeric)
modelFit <- train(trainNumeric$classe ~ . , method="glm", preProcess="pca", data=predict(prep,trainNumeric))
prep <- preProcess(trainNumeric[,-1], method="pca", thresh=.95, outcome = trainNumeric$classe)
prep <- preProcess(trainNumeric[,-1], method="pca", thresh=.95, outcome = trainNumeric[,1])
trainpc <- predict(prep, trainNumeric[,-1])
modelFit <- train(trainNumeric[,1] ~., method="glm", data=trainpc)
?train
modelFit <- train(trainNumeric$classe~., data=trainNumeric, na.action=na.omit, method="glm", preProcess="pca", metric="RMSE")
modelFit <- train(trainNumeric$classe~., data=trainNumeric, na.action=na.omit, method="glm", preProcess="pca", metric="Accuracy")
warnings()
modelFit <- train(trainNumeric$classe~., data=trainNumeric, na.action=na.omit, method="ada", preProcess="pca", metric="Accuracy")
featurePlot(x = trainNumeric[,-1], y=trainNumeric$classe, plot="pairs")
featurePlot(x = trainNumeric[,2:5], y=trainNumeric$classe, plot="pairs")
featurePlot(x = trainNumeric[,2:5], y=trainNumeric$classe, plot="density")
featurePlot(x = trainNumeric[,2:5], y=trainNumeric$classe, plot="scatter")
featurePlot(x = trainNumeric[,2:5], y=trainNumeric$classe, plot="scatter", layout=c(3,1))
featurePlot(x = trainNumeric[,2:5], y=trainNumeric$classe, plot="density")
training <- read.csv("training.csv")
train <- cbind(training[,160], training[, sapply(training, class) %in% c("numeric")])
str(train)
colnames(train)
colnames(train)[1]<-"classe"
summary(train[,1:10])
summary(train[,11:20])
colnames(training)
summary(training$X)
summary(training$user_name)
summary(training$cvtd_timestamp)
summary(training[,1:10])
summary(training[,11:20])
summary(training[,17])
training[,17]
summary(training[,17])
summary(training[,20-30])
str(training[,20-30])
hist(training$classe)
